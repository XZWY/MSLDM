{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import *\n",
    "import sys\n",
    "\n",
    "sys.path.append('./msldm')\n",
    "sys.path.append('./SourceVAE')\n",
    "\n",
    "import audio_diffusion_pytorch\n",
    "from audio_diffusion_pytorch import AudioDiffusionModel\n",
    "\n",
    "from main.module_base_latent import Model\n",
    "import main\n",
    "from models.model.dac_vae import DACVAE\n",
    "from audio_diffusion_pytorch import KarrasSchedule\n",
    "\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_differential(x, sigma, denoise_fn):\n",
    "    d = (x - denoise_fn(x, sigma=sigma)) / sigma \n",
    "    # print(sigma)\n",
    "    return d\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_track(\n",
    "    denoise_fn: Callable,\n",
    "    sigmas: torch.Tensor,\n",
    "    noises: torch.Tensor,\n",
    "    source: Optional[torch.Tensor] = None,\n",
    "    mask: Optional[torch.Tensor] = None,\n",
    "    num_resamples: int = 1,\n",
    "    s_churn: float = 0.0,\n",
    "    differential_fn: Callable = score_differential,\n",
    ") -> torch.Tensor:\n",
    "\n",
    "    x = sigmas[0] * noises\n",
    "    _, num_sources, _  = x.shape    \n",
    "\n",
    "    # Initialize default values\n",
    "    source = torch.zeros_like(x) if source is None else source\n",
    "    mask = torch.zeros_like(x) if mask is None else mask\n",
    "    \n",
    "    sigmas = sigmas.to(x.device)\n",
    "    gamma = min(s_churn / (len(sigmas) - 1), 2**0.5 - 1)\n",
    "    \n",
    "    # Iterate over all timesteps\n",
    "    for i in tqdm(range(len(sigmas) - 1)):\n",
    "        sigma, sigma_next = sigmas[i], sigmas[i+1]\n",
    "\n",
    "        # Noise source to current noise level\n",
    "        noisy_source = source + sigma*torch.randn_like(source)\n",
    "        \n",
    "        for r in range(num_resamples):\n",
    "            # Merge noisy source and current x\n",
    "            x = mask*noisy_source + (1.0 - mask)*x \n",
    "\n",
    "            # Inject randomness\n",
    "            sigma_hat = sigma * (gamma + 1)            \n",
    "            x_hat = x + torch.randn_like(x) * (sigma_hat**2 - sigma**2)**0.5\n",
    "\n",
    "            # Compute conditioned derivative\n",
    "            d = differential_fn(x=x_hat, sigma=sigma_hat, denoise_fn=denoise_fn)\n",
    "\n",
    "            # Update integral\n",
    "            x = x_hat + d*(sigma_next - sigma_hat)\n",
    "                \n",
    "            # Renoise if not last resample step\n",
    "            if r < num_resamples - 1:\n",
    "                x = x + torch.randn_like(x) * (sigma**2 - sigma_next**2)**0.5\n",
    "\n",
    "    return mask*source + (1.0 - mask)*x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set gpu device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### instantiate models (SourceVAE and Latent Diffusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourcevae_ckpt_path = './ckpt/sourcevae_ckpt'\n",
    "from main.module_base_latent import Model\n",
    "# model = Model.load_from_checkpoint('./ckpt/msldm_large.ckpt').to(device)\n",
    "model = Model.load_from_checkpoint('./ckpt/msldm.ckpt').to(device) # use the small model\n",
    "model.eval()\n",
    "denoise_fn = model.model.diffusion.denoise_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate model\n",
    "vae = DACVAE(\n",
    "    encoder_dim = 64,\n",
    "    encoder_rates = [2, 4, 5, 8],\n",
    "    latent_dim = 80,\n",
    "    decoder_dim = 1536,\n",
    "    decoder_rates = [8, 5, 4, 2],\n",
    "    sample_rate = 22050).to(device)\n",
    "\n",
    "# load checkpoints\n",
    "model_ckpt = torch.load(sourcevae_ckpt_path, map_location=device)\n",
    "vae.load_state_dict(model_ckpt['generator'])\n",
    "vae.eval()\n",
    "print('finish loading ckpts from: ', sourcevae_ckpt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation hyper-parameters\n",
    "s_churn = 20.\n",
    "batch_size = 1\n",
    "num_steps = 150\n",
    "num_resamples = 1\n",
    "\n",
    "latent_dim=80\n",
    "\n",
    "# Define timestep schedule\n",
    "schedule = KarrasSchedule(sigma_min=1e-2, sigma_max=3, rho=7)(num_steps, device)\n",
    "\n",
    "# Unconditionally sample from diffusion model\n",
    "generated_tracks = generate_track(\n",
    "    denoise_fn,\n",
    "    sigmas=schedule,\n",
    "    # noises=torch.randn(1, 4, 2**16).to(device),\n",
    "    noises=torch.randn(batch_size, latent_dim*4, 1024).to(device),\n",
    "    s_churn=s_churn,\n",
    "    num_resamples=num_resamples,\n",
    ")\n",
    "bs = generated_tracks.shape[0]\n",
    "generated_tracks = generated_tracks.reshape(bs, 4, latent_dim, -1)\n",
    "generated_tracks = generated_tracks.reshape(bs*4, latent_dim, -1)\n",
    "with torch.no_grad():\n",
    "    waves = vae.decode(generated_tracks)\n",
    "waves = waves.reshape(bs, 4, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waves.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "\n",
    "# Play the audio\n",
    "# waves = waves.cpu().numpy()\n",
    "for i in range(bs):\n",
    "    print(f'sample {str(i)}:')\n",
    "    mixture = np.zeros(waves[0,0].shape)\n",
    "    for j in range(4):\n",
    "        audio = Audio(data=waves[i,j], rate=22050)\n",
    "        mixture += waves[i, j]\n",
    "        display(audio)\n",
    "\n",
    "    print('mixture')\n",
    "    audio = Audio(data=mixture, rate=22050)\n",
    "    display(audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partial Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### impaint function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEMS = [\"bass\",\"drums\",\"guitar\",\"piano\"] # < IMPORTANT: do not change\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_inpaint_mask(sources, stem_to_inpaint: List[int]):\n",
    "    mask = torch.ones_like(sources) # bs, 4, n_samples\n",
    "    for stem_idx in stem_to_inpaint:\n",
    "        mask[:,stem_idx*80:(stem_idx+1)*80:,:] = 0.0\n",
    "    return mask\n",
    "\n",
    "def impaint(\n",
    "        input, \n",
    "        schedule, \n",
    "        denoise_fn,\n",
    "        vae,\n",
    "        stems_to_inpaint=['drums']):\n",
    "    bs = input.shape[0] # bs, 4, n_samples\n",
    "\n",
    "    # input = torch.nn.functional.pad(input, (0, 327672 - 2**18)).to(device)\n",
    "    input = input.reshape(bs*4, -1)\n",
    "    with torch.no_grad():\n",
    "        source_chunk = vae.encode(input.unsqueeze(1)).mode() # bs*4, 80\n",
    "\n",
    "    source_chunk = source_chunk.reshape(bs, 320, 1024)\n",
    "\n",
    "    assert len([s for s in stems_to_inpaint if s not in STEMS]) == 0 # < stems_to_inpaint must be a subset of STEMS\n",
    "    stemidx_to_inpaint = [i for i,s in enumerate(STEMS) if s in stems_to_inpaint]\n",
    "    stemidx_to_condition = [stemidx for stemidx in range(4) if stemidx not in stemidx_to_inpaint]\n",
    "    inpaint_mask = generate_inpaint_mask(source_chunk, stem_to_inpaint=stemidx_to_inpaint) # bs, 320, 1024\n",
    "\n",
    "    inpainted_tracks = generate_track(\n",
    "        source=source_chunk, # bs, 320, 1024\n",
    "        mask=inpaint_mask, #\n",
    "        denoise_fn=denoise_fn,\n",
    "        sigmas=schedule,\n",
    "        noises=torch.randn_like(source_chunk),#.repeat(batch_size, 1, 1),\n",
    "        s_churn=20.0,\n",
    "        num_resamples=1,\n",
    "    )\n",
    "    bs = inpainted_tracks.shape[0]\n",
    "    inpainted_tracks = inpainted_tracks.reshape(bs, 4, 80, -1)\n",
    "    inpainted_tracks = inpainted_tracks.reshape(bs*4, 80, -1)\n",
    "    vae = vae.to(device)\n",
    "    vae.eval()\n",
    "    with torch.no_grad():\n",
    "        waves = vae.decode(inpainted_tracks) #\n",
    "    waves = waves.reshape(bs, 4, -1)\n",
    "\n",
    "    condition = input.reshape(bs, 4, -1)[:, stemidx_to_condition, :].sum(1)\n",
    "    inpaint = waves[:, stemidx_to_inpaint, :].sum(1)\n",
    "    mixture = inpaint + condition\n",
    "\n",
    "    return waves, condition, inpaint, mixture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "\n",
    "def load_track(track_folder: Path, stems: List[str]):\n",
    "    wavs = []\n",
    "    for s in stems:\n",
    "        wav, wav_sr = torchaudio.load(os.path.join(track_folder, f\"{s}.wav\"))\n",
    "        assert wav_sr == 22050\n",
    "        assert wav.shape[0] == 1 # < single channel\n",
    "        wavs += [wav]\n",
    "    return torch.cat(wavs, dim=0).unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load audio track. Shape = [1, num_sources, num_samples]\n",
    "sources = load_track(\"./msldm/data/dummy_slakh2100/test/Track01888\", STEMS).to(device)\n",
    "start_second = 20.0\n",
    "start_sample = int(start_second*22050)\n",
    "source_chunk = sources[:,:, start_sample:start_sample + 327672] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup what to partially generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = [['drums'], ['bass', 'drums']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### partial generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule = KarrasSchedule(sigma_min=1e-2, sigma_max=3.0, rho=7)(150, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_chunk = source_chunk.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_music = {}\n",
    "inpaint_music = {}\n",
    "mixture_music = {}\n",
    "for combo in combinations:\n",
    "    \n",
    "    stems_to_inpaint = combo\n",
    "    combo_name = '_'.join(stems_to_inpaint)\n",
    "    \n",
    "    out_types = ['condition', 'impainted', 'mixture']\n",
    "    waves, condition, inpaint, mixture = impaint(source_chunk, schedule, denoise_fn, vae, stems_to_inpaint=stems_to_inpaint)\n",
    "    condition = condition.cpu().numpy()\n",
    "    inpaint = inpaint.cpu().numpy()\n",
    "    mixture = mixture.cpu().numpy()\n",
    "    condition_music[combo_name] = condition\n",
    "    inpaint_music[combo_name] = inpaint\n",
    "    mixture_music[combo_name] = mixture\n",
    "    print(combo, ' finished')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for combo in combinations:\n",
    "    print(f'---------------------------------------------Generate {combo}------------------------------------------')\n",
    "    combo_name = '_'.join(combo)\n",
    "    print('condition: ')\n",
    "    audio = Audio(data=condition_music[combo_name], rate=22050)\n",
    "    display(audio)\n",
    "    print(f'generated {combo}: ')\n",
    "    audio = Audio(data=inpaint_music[combo_name], rate=22050)\n",
    "    display(audio)\n",
    "    print('mixture: ')\n",
    "    audio = Audio(data=mixture_music[combo_name], rate=22050)\n",
    "    display(audio)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
